# MIT FutureMakers GitHub Repository
## Contents:
   - [Responses Section](#responses)
      - [Week One](#week-one---the-basics)
      - [Week Two](#week-two---cnns-data--machine-learning)
      - [Week Three](#week-three--functions-and-predictions)
## Responses:
### Week One - THE BASICS
   - **Day 1 (07/06/21)**: What I hope to learn from this program is a greater understanding and appreciation for Artificial Intelligence, as well as gain confidence in skills needed for AI. With the information that I will end up learning from this class, I am sure that I will be able to come up with deep learning networks to solve real problems, which is exciting.
   - **Day 2 (07/07/21)**: In Dr. David Kong's Leadership Seminar, I found that everyone has their own story. We live our own lives, which, in his words, is like the ocean that we swim in. We completed an activity where we had to share our own stories. In the beginning, I was nervous, since to me my life just feels *regular*, even if it is not that way to other people. Additionally, I saw that stories, when told well, have the power to create change, and improve the lives we live in. It can mean more than just simply talking about a life event. One of my contributions to my local community was before the shutdown when I was still back in New York City. I loved going to the Liberty Science Center as a kid, so last year, I chose to volunteer there. I wanted to be able to help get kids like me excited about science, technology, and other things, just like the science center had done for me. I hope that my 180+ hours volunteering there has been able to do just that.
   - **Day 3 (07/08/21)**: The difference between supervised and unsupervised learning comes from the interaction of the coder with the classifications that the code is intended to make. Basically, with supervised learning, the person writing the program already pre-labeled the different items. These labels allow the program to become more accurate, by comparing its predictions with the correct answers that were already given. On the other hand, unsupervised learning has no pre-set labels; the network must find its own patterns, and group the data into clusters. By finding the divide between the clusters, the code can predict what the item is by checking if it falls in a specific cluster. 
     - The statement "Scikit-Learn has the power to visualize data without a Graphviz, Pandas, or other data analysis libraries" is false, since Scikit learn works best in conjunction with these libraries, rather than simply instead of them.  
  - **Day 4 (07/09/21)**: I wanted to find a dataset on car accidents across the United States, so that it can be able to predict where and when car accidents are most likely to occur, in order to add extra measures to reduce car accidents in those areas and times. I was able to find such a dataset, found here (https://www.kaggle.com/sobhanmoosavi/us-accidents). I chose this data set, since not only does it contain three million recorded accidents all across the United States, but it also stores latitude, longitude, time, and severity for each car accident. These measures would allow for better predictions to be made as to where most accidents would take place.

### Week Two - CNNS, DATA & MACHINE LEARNING
   - **Day 7 (07/12/21)**: Tensors are matrices, but in three dimensions instead of two. They oftentimes can be represented as a matrix with vectors as its elements. In machine learning, tensors can be used to store data with more than two dimensions. A matrix would only be able to store two dimensions of data, which would not be enough for more complicated machine learning datasets. Something that I noticed with some of the computations done is that pandas has multiple different functions that can easily be used to find different parts of the dataset. The head, tail, sample, and describe functions are example of this: easy access to the data. Additionally, I noticed that actually modeling the neural network took a lot less code than pre-processing the data, which is interesting since most of the internal work is done when modeling/running the neural network.
   - **Day 8 (07/13/21)**: Today, we discussed different ways that neural networks function. Basically, Artificial Neural Networks are made up of a series of connected nodes, organized into separate layers. Each connection between nodes has a corresponding weight that is multiplied to the value that ends up being passed through that connection. In order to produce an output value for a certain layer, the weighted sum is passed into an activation function to better fit the values to the data. After running through all of the nodes, if the network is innaccurate, it goes back through the nodes and adjusts the weights in a process known as backpropogation.
   - **Day 9 (07/14/21)**: In this class, we discussed Convolutional Neural Networks, as opposed to Artificial Neural Networks, as mentioned yesterday, specifically, the convolution layer and the pooling layer. Convolution layers apply a matrix weight to a different, larger matrix, usually representing pixels in an image. It's similar to the functionality of individual neurons in Artificial Neural Networks, except in two dimensions rather than one. The pooling layer, on the other hand, makes the image matrix smaller, either through max pooling or average pooling. Max pooling is where the largest element is used from the feature map, and average pooling is where the average is used instead. This layer is necessary, since it helps to find the important parts of an image, such as edges, curves, and more, while filtering out pixels that are not as relevant. 
   - **Day 10 (07/15/21)**: Machine learning and AI concepts were used to design the game model for "Survival of the Best Fit", since the game had you use a machine learning model to determine who to hire and who to fire for a company. As the game progressed, the machine learning model showed biases towards the blue people, and rejected more of them than the orange ones. It was used to demonstrate how bias can occur in machine learning models, and spread caution relating that. A real world example of a biased machine learning model is the Amazon hiring algorithm. Back in 2015, because more men applied than women, more men got accepted than women; this led to innate bias against women altogether. One potential way to assist in correcting this is by assigning a number to each applicant beforehand, store the numbers and the corresponding names in a list, remove the names, and then pass it on to the algorithm. This may help, since even if gender is not even mentioned in the application, the AI can still form a correlation to it from the appilcants' names. I chose this situation, since I am female, and bias such as this could potentially affect whether or not I get hired to certain jobs in the future.
   - **Day 11 (07/16/21)**:A Fully Connected Neural Network consists of a series of interconnected neurons organized into layers. The first layer is known as the input layer. This is where all of the input values are passed in. All of the layers in the middle are known as the hidden layers. They all function similar manner: take the values coming into it from every node in the previous layer, multiply them by weights determined by the model during backpropogation, and pass the overall sum into an activation function, which generalizes the data. These hidden layers allow to better construct the boundary that separates the data, for a more accurate representation. Finally, we have the output layer, which stores the final value. It functions similarly to all of the hidden layers, except it produces the result for the model. On the other hand, there are four main types of layers in a CNN: the convolution layer, the activation layer, the pooling layer, and the fully connected layer. The convolution layer, as stated a few days ago, removes unneccessary information from the image, by applying a certain filter to it. Next, the activation layer runs an activation function on the result of the previous layer. This way, the model that is formed is able to work on any type of data distribution. Afterwards comes the pooling layer. As mentioned previously, it compresses the matrix into a smaller one, by either taking the average of each quadrant (average pooling) or taking the maximum value from each quadrant (max pooling). Choosing between max and average pooling usually depends on the situation. This removes any excess "noise", to better find edges, corners, and more. Finally, we have the fully connected layer, which functions similarly to a fully connected neural network Another difference between fully connected neural networks and CNNs are the applications. CNNs tend to work much better for image recognition, whereas fullly connected neural netorks are better at identifying data that comes as text.

### Week Three â€“ FUNCTIONS AND PREDICTIONS
   - **Day 14 (07/19/21)**: Loss functions show the error of a neural network. This means that it takes the values that the model predicts and subtracts them from the values that the data should be. In other words, smaller values in the loss function indicate a more accurate result. Parameters can be updated in order to find the model with the minimum loss function, without overfitting. This involves gradient descent, which has three main steps. First, the algorithm must see the effects of a minor change in the weights on the loss function, by calculating the gradient. Then, it must adjust the weights accordingly. Finally, the model has to repeat the previous two parts, until a local minimum is reached. All of this allows for the model to be optimized.
